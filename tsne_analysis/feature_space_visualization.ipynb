{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from models import model_dict\n",
    "from utils import NormalizeByChannelMeanStd\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder\n",
    "from dataset import prepare_train_test_dataset\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from utils.evaluation import Hook_handle, analysis, get_micro_eval, get_acc, get_micro_eval_seperate_correct\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = ['cifar10', 'cifar100', 'TinyImagenet', 'TinyImagenet']\n",
    "architecture = ['resnet18', 'resnet50', 'resnet18', 'vgg16_bn']\n",
    "\n",
    "backdata = {}\n",
    "for arch, data in zip(architecture, dataset):\n",
    "    for us in range(3):\n",
    "        with open(f\"assets/feature_topo_analysis/{data}_{arch}_unlearn_seed_{us}_feature_label.pkl\", \"rb\") as f:\n",
    "            seed_dict = pickle.load(f)\n",
    "            backdata[(data, arch, us)] = seed_dict\n",
    "\n",
    "            # features = seed_dict[0]['retrain_feature'][target]\n",
    "            # labels = seed_dict[0]['retrain_label'][target]\n",
    "            # weights = seed_dict[0]['retrain_weight'][target]\n",
    "            # bias = seed_dict[0]['retrain_bias'][target]\n",
    "            # print((torch.max(features @ weights.T + bias, dim=1).indices == labels).sum() / len(torch.max(features @ weights.T + bias, dim=1).indices == labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "target = 'forget'\n",
    "# init_seed = 0\n",
    "# arch, data = 'resnet18', 'cifar10'\n",
    "# us = 0\n",
    "\n",
    "for arch, data, NUM_CLASS_VISIBLE, alpha, perplexity in zip(architecture, dataset, [3, 6, 12, 12], [0.5, 0.5, 0.5, 0.5], [30, 10, 5, 5]):\n",
    "    for us in range(3): # 3\n",
    "       for init_seed in range(3): # 3 \n",
    "            confidences = backdata[(data, arch, us)][init_seed]['orig_confidence'][target]\n",
    "            weights = backdata[(data, arch, us)][init_seed][f'orig_weight'][target]\n",
    "            # confidences = backdata[(data, arch, 0)][init_seed]['retrain_confidence'][target]\n",
    "            # NUM_CLASS_VISIBLE = 3\n",
    "            target_labels = np.random.choice(np.arange(weights.shape[0]), size=NUM_CLASS_VISIBLE, replace=False).astype(int)\n",
    "            target_labels.sort()\n",
    "            target_labels\n",
    "            palette = sns.color_palette(\"tab10\", n_colors=weights.shape[0])\n",
    "\n",
    "\n",
    "            for mode in ['orig', 'retrain']:\n",
    "                features = backdata[(data, arch, 0)][init_seed][f'{mode}_feature'][target]\n",
    "                labels = backdata[(data, arch, 0)][init_seed][f'{mode}_label'][target]\n",
    "                weights = backdata[(data, arch, 0)][init_seed][f'{mode}_weight'][target]\n",
    "                bias = backdata[(data, arch, 0)][init_seed][f'{mode}_bias'][target]\n",
    "                print((torch.max(features @ weights.T + bias, dim=1).indices == labels).sum() / len(torch.max(features @ weights.T + bias, dim=1).indices == labels))\n",
    "                \n",
    "                features_np = features.numpy()\n",
    "                labels_np = labels.numpy()\n",
    "                confidences_np = confidences.numpy()\n",
    "                weights_np = weights.cpu().numpy()\n",
    "                bias_np = bias.cpu().numpy()\n",
    "                conf_norm = np.argsort(np.argsort(confidences_np)) / (len(confidences_np) - 1) \n",
    "\n",
    "\n",
    "                mask = np.isin(labels_np, target_labels)\n",
    "                features_np = features_np[mask]\n",
    "                labels_np = labels_np[mask]\n",
    "                confidences_np = confidences_np[mask]\n",
    "                weights_np = weights_np[target_labels]\n",
    "                bias_np = bias_np[target_labels]\n",
    "                conf_norm = conf_norm[mask]\n",
    "                \n",
    "\n",
    "                # tsne = TSNE(n_components=2, random_state=42, perplexity=50)\n",
    "                tsne = TSNE(n_components=2, perplexity=perplexity, metric='cosine') #  \n",
    "                features_np = features_np / np.linalg.norm(features_np, axis=1, keepdims=True)\n",
    "                weights_np = weights_np / np.linalg.norm(weights_np, axis=1, keepdims=True)\n",
    "                tsne_all_input = np.concatenate([features_np, weights_np], axis=0) # , np.zeros((1, weights_np.shape[1]))\n",
    "                tsne_all_input = tsne_all_input @ weights_np.T\n",
    "                tsne_all_output = tsne.fit_transform(tsne_all_input)\n",
    "\n",
    "                features_tsne = tsne_all_output[:features_np.shape[0]]\n",
    "                weight_tsne = tsne_all_output[features_np.shape[0]:]\n",
    "                # zero_point = tsne_all_output[-1]\n",
    "\n",
    "                import matplotlib.colors as mcolors\n",
    "                for qwer, title in enumerate(['low_conf', 'high_conf']):\n",
    "                    plt.figure(figsize=(3, 3))\n",
    "                    # plt.scatter(zero_point[0], zero_point[1],\n",
    "                    #                 color='k', edgecolors='k', marker='o', s=100, linewidths=1.5)\n",
    "\n",
    "                    white = np.array([1.0, 1.0, 1.0])\n",
    "                    custom_legend = []\n",
    "                    for i, label in enumerate(target_labels): #range(weights.shape[0]):\n",
    "\n",
    "                        idx = labels_np == label\n",
    "                        low_conf_mask = (conf_norm < alpha) & idx  \n",
    "                        high_conf_mask = (~low_conf_mask) & idx\n",
    "\n",
    "                        base_color = np.array(palette[int(i)])\n",
    "\n",
    "                        # alphas = 1.0 - conf_norm[idx] ** 2 # \n",
    "                        # colors = [tuple(alpha * base_color + (1 - alpha) * white) for alpha in alphas]\n",
    "                        plt.scatter(weight_tsne[i, 0], weight_tsne[i, 1],\n",
    "                                    color=base_color*0.6, edgecolors='k', marker='D', s=50, linewidths=1.5,\n",
    "                                    label=f'Weight{int(label)}', zorder=1)\n",
    "\n",
    "                        # plt.scatter(features_tsne[idx, 0], features_tsne[idx, 1],\n",
    "                        #             color=colors, s=40, label=f'Label {int(label)}', edgecolors='none')\n",
    "\n",
    "                        zorders_low = np.random.uniform(1.5, 2.5, size=features_tsne[low_conf_mask].shape[0])\n",
    "                        zorders_high = np.random.uniform(1.5, 2.5, size=features_tsne[high_conf_mask].shape[0])\n",
    "\n",
    "\n",
    "               \n",
    "                        alphas_low = 1.0 - conf_norm[low_conf_mask] ** 2 # \n",
    "                        # colors_low = [tuple(alpha * base_color + (1 - alpha) * white) for alpha in alphas_low]\n",
    "                        colors_low = base_color\n",
    "                        alphas_high = 1.0 -  conf_norm[high_conf_mask] ** 2 # \n",
    "                        # colors_high = [tuple(alpha * base_color + (1 - alpha) * white) for alpha in alphas_high]\n",
    "                        colors_high = base_color\n",
    "                        \n",
    "                        if qwer == 0: # Low confidence points\n",
    "                            for pt, z in zip(features_tsne[low_conf_mask], zorders_low):\n",
    "                                plt.scatter(pt[0], pt[1],\n",
    "                                            color=base_color, s=60, edgecolors='none',\n",
    "                                            marker='o', zorder=z, alpha=0.5, label=f'class{int(label)}')\n",
    "                        elif qwer == 1: # High confidence points\n",
    "                            for pt, z in zip(features_tsne[high_conf_mask], zorders_high):\n",
    "                                plt.scatter(pt[0], pt[1],\n",
    "                                            color=base_color, s=60, edgecolors='none',\n",
    "                                            marker='o', zorder=z, alpha=0.5, label=f'class{int(label)}')\n",
    "                                            \n",
    "                 \n",
    "                    # Weight \n",
    "                    import matplotlib.lines as mlines\n",
    "                    import matplotlib.patches as mpatches\n",
    "                    weight_patch = mlines.Line2D([], [], color='k',\n",
    "                                                marker='D', linestyle='None',\n",
    "                                                markeredgecolor='k', markersize=6, label=f'Weight')\n",
    "                    \n",
    "                    # Low confidence \n",
    "                    circ_patch = mlines.Line2D([], [], color='k', alpha=0.5,\n",
    "                                            marker='o', linestyle='None',\n",
    "                                            markersize=6, label=f'Feature')\n",
    "                    custom_legend.extend([weight_patch, circ_patch])\n",
    "                    plt.legend(\n",
    "                        handles=custom_legend,\n",
    "                        loc='upper center',\n",
    "                        bbox_to_anchor=(0.5, 1.12),  \n",
    "                        fontsize=8,\n",
    "                        ncol=3,\n",
    "                        frameon=True,\n",
    "                        handletextpad=0.5,  \n",
    "                        columnspacing=1.6,  \n",
    "                        handlelength=1.2    \n",
    "                    )\n",
    "                    # plt.title(\"t-SNE of Original Features\\n(Confidence â†’ Saturation)\")\n",
    "                    # plt.xlabel(\"Component 1\")\n",
    "                    # plt.ylabel(\"Component 2\")\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    plt.tight_layout()\n",
    "                    plt.grid(True)\n",
    "\n",
    "                    plt.savefig(f'assets/feature_topo_analysis_figure/{data}_{arch}_unlearn_seed_{us}_init_seed_{init_seed}_tsne_{mode}_{title}.pdf', bbox_inches='tight', format='pdf')\n",
    "                    print(mode, title)\n",
    "                    plt.show()\n",
    "                    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
