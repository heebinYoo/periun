{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from models import model_dict\n",
    "from utils import NormalizeByChannelMeanStd\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10, CIFAR100, ImageFolder\n",
    "from dataset import prepare_train_test_dataset\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from utils.evaluation import Hook_handle, analysis, get_micro_eval, get_acc, get_micro_eval_seperate_correct\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "from types import SimpleNamespace\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "dataset = ['cifar10', 'cifar100', 'TinyImagenet', 'TinyImagenet'] # \n",
    "architecture = ['resnet18', 'resnet50', 'resnet18', 'vgg16_bn']\n",
    "\n",
    "\n",
    "\n",
    "target = 'forget'\n",
    "\n",
    "for method in [\"randomlabel_salun\", \"randomlabel\"]:\n",
    "    for arch, data in zip(architecture, dataset):\n",
    "        for us in range(1):\n",
    "            train_loader, test_loader, forget_loader, retain_loader, normalization, classes = prepare_train_test_dataset(data, 0, 256, us)\n",
    "            with open(f\"assets/feature_topo_analysis/{data}_{arch}_unlearn_seed_{us}_feature_label.pkl\", \"rb\") as f:\n",
    "                backdata = pickle.load(f)\n",
    "            with open(f\"assets/unlearn_feature_topo_analysis/{method}_{data}_{arch}_unlearn_seed_{us}_feature_label.pkl\", \"rb\") as f:\n",
    "                backdata_unlearn = pickle.load(f)\n",
    "            for init_seed in range(1):\n",
    "                orig_feature = backdata[init_seed]['orig_feature'][target]\n",
    "                retrain_feature = backdata[init_seed]['retrain_feature'][target]\n",
    "                standard_feature = backdata_unlearn[init_seed]['standard_feature'][target]\n",
    "                periun_feature = backdata_unlearn[init_seed]['periun_feature'][target]\n",
    "\n",
    "                orig_weight = backdata[init_seed]['orig_weight'][target]\n",
    "                retrain_weight = backdata[init_seed]['retrain_weight'][target]\n",
    "                standard_weight = backdata_unlearn[init_seed]['standard_weight'][target]\n",
    "                periun_weight = backdata_unlearn[init_seed]['periun_weight'][target]\n",
    "\n",
    "                orig_bias = backdata[init_seed]['orig_bias'][target]\n",
    "                retrain_bias = backdata[init_seed]['retrain_bias'][target]\n",
    "                standard_bias = backdata_unlearn[init_seed]['standard_bias'][target]\n",
    "                periun_bias = backdata_unlearn[init_seed]['periun_bias'][target]\n",
    "\n",
    "                orig_pred = torch.max(orig_feature @ orig_weight.T + orig_bias, dim=1).indices\n",
    "                retrain_pred = torch.max(retrain_feature @ retrain_weight.T + retrain_bias, dim=1).indices\n",
    "                standard_pred = torch.max(standard_feature @ standard_weight.T + standard_bias, dim=1).indices\n",
    "                periun_pred = torch.max(periun_feature @ periun_weight.T + periun_bias, dim=1).indices\n",
    "                \n",
    "                label = backdata[init_seed]['retrain_label'][target]\n",
    "\n",
    "                orig_correct = (orig_pred == label)\n",
    "                retrain_correct = (retrain_pred == label)\n",
    "                retrain_fliped = (~retrain_correct) & orig_correct\n",
    "\n",
    "                standard_correct = (standard_pred == label)\n",
    "                standard_fliped = (~standard_correct) & orig_correct\n",
    "                periun_correct = (periun_pred == label)\n",
    "                periun_fliped = (~periun_correct) & orig_correct\n",
    "\n",
    "                retrain_standard_agreement = torch.sum(retrain_fliped == standard_fliped).item() / retrain_correct.shape[0]\n",
    "                retrain_periun_agreement = torch.sum(retrain_fliped == periun_fliped).item() / retrain_correct.shape[0]\n",
    "                print(f\"fliped Agreement {method} {data} {arch} {us} {init_seed}: retrain_standard_agreement: {retrain_standard_agreement:.2f}, retrain_periun_agreement: {retrain_periun_agreement:.2f}\")\n",
    "            \n",
    "                orig_conf = backdata[init_seed]['orig_confidence'][target]\n",
    "                retrain_conf = backdata[init_seed]['retrain_confidence'][target]\n",
    "                standard_conf = backdata_unlearn[init_seed]['standard_confidence'][target]\n",
    "                periun_conf = backdata_unlearn[init_seed]['periun_confidence'][target]\n",
    "\n",
    "                retrain_fliped_conf = orig_conf[retrain_fliped]\n",
    "                standard_fliped_conf = orig_conf[standard_fliped]\n",
    "                periun_fliped_conf = orig_conf[periun_fliped]\n",
    "\n",
    "                top10_indices = orig_conf.argsort(descending=True)[:10]\n",
    "\n",
    "                images = [forget_loader.dataset[idx][0].permute(1, 2, 0) for idx in top10_indices]\n",
    "\n",
    "                # titles = [f'Top-{i+1}' for i in range(15)]\n",
    "\n",
    "                fig, axes = plt.subplots(2, 5, figsize=(5.5, 2))  \n",
    "                for ax, img in zip(axes.flatten(), images):\n",
    "                    ax.imshow(img, vmin=0, vmax=1)\n",
    "                    # ax.set_title(title)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f'assets/final_quantative/{method}_{data}_{arch}_{us}_{init_seed}_vispic.pdf', bbox_inches='tight', format='pdf')\n",
    "                plt.show()\n",
    "\n",
    "                top15_indices = orig_conf.argsort(descending=True)[:15]\n",
    "\n",
    "                flags = {\n",
    "                    'Retrain': retrain_fliped[top15_indices].tolist(),\n",
    "                    'Standard': standard_fliped[top15_indices].tolist(),\n",
    "                    'Periun': periun_fliped[top15_indices].tolist()\n",
    "                }\n",
    "                # flags = {\n",
    "                #     'Retrain': ~retrain_correct[top15_indices].tolist(),\n",
    "                #     'Standard': ~standard_correct[top15_indices].tolist(),\n",
    "                #     'Periun': ~periun_correct[top15_indices].tolist()\n",
    "                # }\n",
    "\n",
    "\n",
    "\n",
    "                cell_width = 0.35\n",
    "                cell_height = 0.4\n",
    "                h_gap = 0.1\n",
    "                v_gap = 0.2\n",
    "\n",
    "                n_cols = len(next(iter(flags.values())))\n",
    "                n_rows = len(flags)\n",
    "\n",
    "                fig_width = n_cols * (cell_width + h_gap)\n",
    "                fig_height = n_rows * (cell_height + v_gap) - v_gap\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "                row_labels = [r'$\\mathcal{M}_r$', r'$\\mathcal{M}_\\text{base}$', r'$\\mathcal{M}_\\text{ours}$']\n",
    "\n",
    "\n",
    "                for row_idx, (label, values) in enumerate(flags.items()):\n",
    "                    for col_idx, val in enumerate(values):\n",
    "                        x = col_idx * (cell_width + h_gap)\n",
    "                        y = -row_idx * (cell_height + v_gap)\n",
    "                        color = 'red' if val else 'green'\n",
    "                        rect = Rectangle((x, y), cell_width, cell_height, facecolor=color, edgecolor='black')\n",
    "                        ax.add_patch(rect)\n",
    "     \n",
    "                    ax.text(-0.2, y + cell_height / 2, row_labels[row_idx], va='center', ha='right', fontsize=25)\n",
    "\n",
    "                \n",
    "                x_max = n_cols * (cell_width + h_gap) - h_gap\n",
    "                y_min = -n_rows * (cell_height + v_gap) + v_gap + v_gap + 0.175\n",
    "\n",
    "                ax.set_xlim(-1, x_max) \n",
    "                ax.set_ylim(y_min, cell_height)\n",
    "                ax.set_aspect('equal')\n",
    "                ax.axis('off')\n",
    "\n",
    "                plt.savefig(f'assets/final_quantative/{method}_{data}_{arch}_{us}_{init_seed}_filped.pdf', bbox_inches='tight', format='pdf')\n",
    "                plt.show()\n",
    "            \n",
    "            del backdata, backdata_unlearn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
